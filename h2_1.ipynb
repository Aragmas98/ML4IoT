{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import tensorflow.lite as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup a random seed\n",
    "seed = 42\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "# Make sure we don't get any GPU errors\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data downloading and train-test-val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>Tpot (K)</th>\n",
       "      <th>Tdew (degC)</th>\n",
       "      <th>rh (%)</th>\n",
       "      <th>VPmax (mbar)</th>\n",
       "      <th>VPact (mbar)</th>\n",
       "      <th>VPdef (mbar)</th>\n",
       "      <th>sh (g/kg)</th>\n",
       "      <th>H2OC (mmol/mol)</th>\n",
       "      <th>rho (g/m**3)</th>\n",
       "      <th>wv (m/s)</th>\n",
       "      <th>max. wv (m/s)</th>\n",
       "      <th>wd (deg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2009 00:10:00</td>\n",
       "      <td>996.52</td>\n",
       "      <td>-8.02</td>\n",
       "      <td>265.40</td>\n",
       "      <td>-8.90</td>\n",
       "      <td>93.3</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.94</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1307.75</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.75</td>\n",
       "      <td>152.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.2009 00:20:00</td>\n",
       "      <td>996.57</td>\n",
       "      <td>-8.41</td>\n",
       "      <td>265.01</td>\n",
       "      <td>-9.28</td>\n",
       "      <td>93.4</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.89</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1309.80</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.50</td>\n",
       "      <td>136.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.2009 00:30:00</td>\n",
       "      <td>996.53</td>\n",
       "      <td>-8.51</td>\n",
       "      <td>264.91</td>\n",
       "      <td>-9.31</td>\n",
       "      <td>93.9</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.88</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1310.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.63</td>\n",
       "      <td>171.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.01.2009 00:40:00</td>\n",
       "      <td>996.51</td>\n",
       "      <td>-8.31</td>\n",
       "      <td>265.12</td>\n",
       "      <td>-9.07</td>\n",
       "      <td>94.2</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1309.19</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.01.2009 00:50:00</td>\n",
       "      <td>996.51</td>\n",
       "      <td>-8.27</td>\n",
       "      <td>265.15</td>\n",
       "      <td>-9.04</td>\n",
       "      <td>94.1</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.09</td>\n",
       "      <td>1309.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.63</td>\n",
       "      <td>214.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Time  p (mbar)  T (degC)  Tpot (K)  Tdew (degC)  rh (%)  \\\n",
       "0  01.01.2009 00:10:00    996.52     -8.02    265.40        -8.90    93.3   \n",
       "1  01.01.2009 00:20:00    996.57     -8.41    265.01        -9.28    93.4   \n",
       "2  01.01.2009 00:30:00    996.53     -8.51    264.91        -9.31    93.9   \n",
       "3  01.01.2009 00:40:00    996.51     -8.31    265.12        -9.07    94.2   \n",
       "4  01.01.2009 00:50:00    996.51     -8.27    265.15        -9.04    94.1   \n",
       "\n",
       "   VPmax (mbar)  VPact (mbar)  VPdef (mbar)  sh (g/kg)  H2OC (mmol/mol)  \\\n",
       "0          3.33          3.11          0.22       1.94             3.12   \n",
       "1          3.23          3.02          0.21       1.89             3.03   \n",
       "2          3.21          3.01          0.20       1.88             3.02   \n",
       "3          3.26          3.07          0.19       1.92             3.08   \n",
       "4          3.27          3.08          0.19       1.92             3.09   \n",
       "\n",
       "   rho (g/m**3)  wv (m/s)  max. wv (m/s)  wd (deg)  \n",
       "0       1307.75      1.03           1.75     152.3  \n",
       "1       1309.80      0.72           1.50     136.1  \n",
       "2       1310.24      0.19           0.63     171.6  \n",
       "3       1309.19      0.34           0.50     198.0  \n",
       "4       1309.00      0.32           0.63     214.3  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_path = tf.keras.utils.get_file(\n",
    "    origin=\"https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip\", \n",
    "    fname='jena_climate_2009_2016.csv.zip', \n",
    "    extract=True, \n",
    "    cache_dir='.', cache_subdir='data')\n",
    "\n",
    "csv_path, _ = os.path.splitext(zip_path)\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.02, 93.3 ],\n",
       "       [-8.41, 93.4 ],\n",
       "       [-8.51, 93.9 ],\n",
       "       [-8.31, 94.2 ],\n",
       "       [-8.27, 94.1 ]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_indices = [2,5]\n",
    "columns = df.columns[column_indices]\n",
    "data = df[columns].values.astype(np.float32)\n",
    "\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(data)\n",
    "train_data = data[0:int(n*0.7)]\n",
    "val_data = data[int(n*0.7):int(n*0.9)]\n",
    "test_data = data[int(n*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "std = train_data.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Window generator and Multiple-Output_MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator:\n",
    "    def __init__(self, input_width, label_width, num_features, mean, std):\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.num_features = num_features\n",
    "        self.mean = tf.reshape(tf.convert_to_tensor(mean), [1, 1, 2])\n",
    "        self.std = tf.reshape(tf.convert_to_tensor(std), [1, 1, 2])\n",
    "\n",
    "    def split_window(self, features):\n",
    "        # features -> set of sequences made of input_width + label_width values each. [#batch, (input+label)_width, 2] \n",
    "        inputs = features[:, :-self.label_width, :]\n",
    "        labels = features[:, -self.label_width:, :]\n",
    "\n",
    "        inputs.set_shape([None, self.input_width, self.num_features])\n",
    "        labels.set_shape([None, self.label_width, self.num_features])\n",
    "        \n",
    "        return inputs, labels\n",
    "\n",
    "    def normalize(self, features):\n",
    "        features = (features - self.mean) / (self.std + 1.e-6)\n",
    "\n",
    "        return features\n",
    "\n",
    "    def preprocess(self, features):\n",
    "        inputs, labels = self.split_window(features)\n",
    "        inputs = self.normalize(inputs)\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def make_dataset(self, data, reshuffle):\n",
    "        # Creates a dataset of sliding windows over a timeseries provided as array\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "                data=data, # consecutive data points\n",
    "                targets=None, # None -> the dataset will only yield the input data\n",
    "                sequence_length=self.input_width + self.label_width, # Length of the output sequences\n",
    "                sequence_stride=1, # Period between successive output sequences\n",
    "                batch_size=32) # Number of timeseries samples in each batch \n",
    "        \n",
    "        # from each set of sequences it splits data to get input and labels and then normalize\n",
    "        ds = ds.map(self.preprocess)\n",
    "\n",
    "        # so the mapping is done only once\n",
    "        ds = ds.cache()\n",
    "        if reshuffle:\n",
    "            ds = ds.shuffle(100, reshuffle_each_iteration=True)\n",
    "\n",
    "        return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputMAE(tf.keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name='mean_absolute_error', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.total = self.add_weight('total', initializer='zeros', shape=(2,))\n",
    "        self.count = self.add_weight('count', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None): \n",
    "        error = tf.abs(y_pred - y_true)\n",
    "        error = tf.reduce_mean(error, axis=[0,1])\n",
    "        self.total.assign_add(error)\n",
    "        self.count.assign_add(1.)\n",
    "        return\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.count.assign(tf.zeros_like(self.count))\n",
    "        self.total.assign(tf.zeros_like(self.total))\n",
    "    \n",
    "    def result(self):\n",
    "        result = tf.math.divide_no_nan(self.total, self.count)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_width = 6\n",
    "label_width = 6# 3 or 9\n",
    "num_features = 2\n",
    "\n",
    "generator = WindowGenerator(input_width, label_width, num_features, mean=mean, std=std)\n",
    "train_ds = generator.make_dataset(train_data, reshuffle=True)\n",
    "val_ds = generator.make_dataset(val_data, reshuffle=False)\n",
    "test_ds = generator.make_dataset(test_data, reshuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(), \n",
    "    tf.keras.layers.Dense(units=128, activation='relu'), \n",
    "    tf.keras.layers.Dense(units=128, activation='relu'), \n",
    "    tf.keras.layers.Dense(units=num_features*label_width),\n",
    "    tf.keras.layers.Reshape([6, 2])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.MeanSquaredError()\n",
    "optimizer = tf.optimizers.Adam()\n",
    "metrics = [MultiOutputMAE()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'mlp'\n",
    "ID = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9200/9200 [==============================] - 46s 5ms/step - loss: 51.8229 - mean_absolute_error: 2.6848 - val_loss: 5.6266 - val_mean_absolute_error: 1.5900\n",
      "Epoch 2/20\n",
      "9200/9200 [==============================] - 44s 5ms/step - loss: 5.0697 - mean_absolute_error: 1.3029 - val_loss: 4.3366 - val_mean_absolute_error: 1.2043\n",
      "Epoch 3/20\n",
      "9200/9200 [==============================] - 45s 5ms/step - loss: 4.8859 - mean_absolute_error: 1.2659 - val_loss: 5.8181 - val_mean_absolute_error: 1.4700\n",
      "Epoch 4/20\n",
      "9200/9200 [==============================] - 45s 5ms/step - loss: 4.6636 - mean_absolute_error: 1.2388 - val_loss: 4.9440 - val_mean_absolute_error: 1.3215\n",
      "Epoch 5/20\n",
      "9200/9200 [==============================] - 48s 5ms/step - loss: 4.6031 - mean_absolute_error: 1.2302 - val_loss: 5.8244 - val_mean_absolute_error: 1.3916\n",
      "Epoch 6/20\n",
      "9200/9200 [==============================] - 46s 5ms/step - loss: 4.4745 - mean_absolute_error: 1.2033 - val_loss: 5.0801 - val_mean_absolute_error: 1.3848\n",
      "Epoch 7/20\n",
      "9200/9200 [==============================] - 48s 5ms/step - loss: 4.4513 - mean_absolute_error: 1.1939 - val_loss: 5.0882 - val_mean_absolute_error: 1.4285\n",
      "Epoch 8/20\n",
      "9200/9200 [==============================] - 48s 5ms/step - loss: 4.3775 - mean_absolute_error: 1.1837 - val_loss: 5.7351 - val_mean_absolute_error: 1.4605\n",
      "Epoch 9/20\n",
      "9200/9200 [==============================] - 43s 5ms/step - loss: 4.3198 - mean_absolute_error: 1.1736 - val_loss: 4.1988 - val_mean_absolute_error: 1.1071\n",
      "Epoch 10/20\n",
      "9200/9200 [==============================] - 41s 4ms/step - loss: 4.3288 - mean_absolute_error: 1.1738 - val_loss: 4.1411 - val_mean_absolute_error: 1.1686\n",
      "Epoch 11/20\n",
      "9200/9200 [==============================] - 43s 5ms/step - loss: 4.2911 - mean_absolute_error: 1.1582 - val_loss: 4.1787 - val_mean_absolute_error: 1.1418\n",
      "Epoch 12/20\n",
      "9200/9200 [==============================] - 46s 5ms/step - loss: 4.2680 - mean_absolute_error: 1.1553 - val_loss: 3.9476 - val_mean_absolute_error: 1.0373\n",
      "Epoch 13/20\n",
      "9200/9200 [==============================] - 46s 5ms/step - loss: 4.2545 - mean_absolute_error: 1.1532 - val_loss: 4.0280 - val_mean_absolute_error: 1.0705\n",
      "Epoch 14/20\n",
      "9200/9200 [==============================] - 45s 5ms/step - loss: 4.2544 - mean_absolute_error: 1.1536 - val_loss: 4.0807 - val_mean_absolute_error: 1.0523\n",
      "Epoch 15/20\n",
      "9200/9200 [==============================] - 46s 5ms/step - loss: 4.1793 - mean_absolute_error: 1.1360 - val_loss: 5.6036 - val_mean_absolute_error: 1.4623\n",
      "Epoch 16/20\n",
      "9200/9200 [==============================] - 44s 5ms/step - loss: 4.1953 - mean_absolute_error: 1.1373 - val_loss: 4.4917 - val_mean_absolute_error: 1.2485\n",
      "Epoch 17/20\n",
      "9200/9200 [==============================] - 44s 5ms/step - loss: 4.1873 - mean_absolute_error: 1.1338 - val_loss: 4.1397 - val_mean_absolute_error: 1.1461\n",
      "Epoch 18/20\n",
      "9200/9200 [==============================] - 46s 5ms/step - loss: 4.1530 - mean_absolute_error: 1.1313 - val_loss: 4.4860 - val_mean_absolute_error: 1.2293\n",
      "Epoch 19/20\n",
      "9200/9200 [==============================] - 47s 5ms/step - loss: 4.1161 - mean_absolute_error: 1.1214 - val_loss: 4.9728 - val_mean_absolute_error: 1.2909\n",
      "Epoch 20/20\n",
      "9200/9200 [==============================] - 48s 5ms/step - loss: 4.1292 - mean_absolute_error: 1.1244 - val_loss: 4.1453 - val_mean_absolute_error: 1.1222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22e71650f88>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=20, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 12)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               1664      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 12)                1548      \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 6, 2)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,724\n",
      "Trainable params: 19,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 265.875 Kilobytes\n"
     ]
    }
   ],
   "source": [
    "MODEL_FILE_NAME = f'{MODEL}_{ID}_model.h5'\n",
    "\n",
    "if not os.path.exists(f'./models/{MODEL}_{ID}/'):\n",
    "    os.makedirs(f'./models/{MODEL}_{ID}/')\n",
    "\n",
    "saved_model_dir = os.path.join(f'./models/{MODEL}_{ID}/', MODEL_FILE_NAME)\n",
    "\n",
    "model.save(saved_model_dir)\n",
    "\n",
    "print('File size: ' + str(round(os.path.getsize(saved_model_dir)/1024, 4)) + ' Kilobytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1314/1314 [==============================] - 4s 3ms/step - loss: 4.2723 - mean_absolute_error: 1.1645\n",
      "Error:  [0.45298815 1.8760308 ]\n"
     ]
    }
   ],
   "source": [
    "loss, error = model.evaluate(test_ds)\n",
    "print('Error: ', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data.experimental.save(train_ds, './th_train')\n",
    "# tf.data.experimental.save(val_ds, './th_val')\n",
    "tf.data.experimental.save(test_ds, './th_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save TF Lite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\juanm\\AppData\\Local\\Temp\\tmp3640ywgl\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\juanm\\AppData\\Local\\Temp\\tmp3640ywgl\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81932"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_FILE_NAME = f'{MODEL}_{ID}_model.tflite'\n",
    "\n",
    "saved_model_dir = os.path.join(f'./models/{MODEL}_{ID}/', MODEL_FILE_NAME)\n",
    "\n",
    "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = tf_lite_converter.convert()\n",
    "\n",
    "open(saved_model_dir, 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 80.0117 Kilobytes\n"
     ]
    }
   ],
   "source": [
    "print('File size: ' + str(round(os.path.getsize(saved_model_dir)/1024, 4)) + ' Kilobytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On the edge side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_width = 6\n",
    "# label_width = 6# 3 or 9\n",
    "# num_features = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = 'mlp'\n",
    "# ID = 100\n",
    "# MODEL_FILE_NAME = f'{MODEL}_{ID}_model.tflite'\n",
    "# saved_model_dir = os.path.join(f'./models/{MODEL}_{ID}/', MODEL_FILE_NAME)\n",
    "\n",
    "TEST_DIR = './th_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_specs = (tf.TensorSpec([None, input_width, num_features], dtype=tf.float32),\n",
    " tf.TensorSpec([None,label_width, num_features]))\n",
    "\n",
    "test_ds = tf.data.experimental.load(TEST_DIR, tensor_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 6, 2), (None, 6, 2)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = test_ds.unbatch().batch(1)\n",
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=saved_model_dir)\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4529724012219051\n",
      "1.8758937596622667\n"
     ]
    }
   ],
   "source": [
    "error = 0\n",
    "for i,(input, labels) in enumerate(test_ds):\n",
    "    interpreter.set_tensor(input_details[0]['index'], input)\n",
    "    interpreter.invoke()\n",
    "    tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "    mae = np.mean(np.abs(tflite_model_predictions - labels), axis=1)\n",
    "\n",
    "    error = error + mae\n",
    "\n",
    "error_temp = error[0,0]/(i+1)\n",
    "error_hum = error[0,1]/(i+1)\n",
    "\n",
    "print('T MAE: ', error_temp)\n",
    "print('Rh MAE:', error_hum)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b07df32797ebab3fa70d4a9f70db79d16446676c9594683b5222a41098e20e60"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
